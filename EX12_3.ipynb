{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4601c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809972ac",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "85d8f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7600f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94403</th>\n",
       "      <td>Teesta river is lifeline of North Bengal: Mama...</td>\n",
       "      <td>Following PM Narendra Modi and his Bangladeshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58954</th>\n",
       "      <td>Karnataka journalist changes his name to 'Regr...</td>\n",
       "      <td>A Karnataka-based citizen journalist, formerly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61347</th>\n",
       "      <td>Idea, Vodafone to sell tower assets to ATC for...</td>\n",
       "      <td>Idea Cellular and Vodafone India on Monday sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83226</th>\n",
       "      <td>North Korea compares Donald Trump to Hitler</td>\n",
       "      <td>North Korea on Tuesday likened US President Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53119</th>\n",
       "      <td>Delhi boy treated after worms suck 22 litres b...</td>\n",
       "      <td>A 14-year-old anaemic boy, who received repeat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70869</th>\n",
       "      <td>Priyanka responds to user trolling her work fo...</td>\n",
       "      <td>Priyanka Chopra responded to a user on Twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25622</th>\n",
       "      <td>Mom Sridevi was worried about my comparison wi...</td>\n",
       "      <td>Janhvi Kapoor has said her late mother and act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>Nawazuddin's 'Photograph' to screen at Berlin ...</td>\n",
       "      <td>Nawazuddin Siddiqui and Sanya Malhotra starrer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46262</th>\n",
       "      <td>Congress deletes 'Sridevi awarded Padma Shri b...</td>\n",
       "      <td>In a tweet mourning actress Sridevi's demise, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87568</th>\n",
       "      <td>Poster of Rajinikanth's Tamil film Kaala Karik...</td>\n",
       "      <td>The first look poster of Rajinikanth's Tamil f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "94403  Teesta river is lifeline of North Bengal: Mama...   \n",
       "58954  Karnataka journalist changes his name to 'Regr...   \n",
       "61347  Idea, Vodafone to sell tower assets to ATC for...   \n",
       "83226        North Korea compares Donald Trump to Hitler   \n",
       "53119  Delhi boy treated after worms suck 22 litres b...   \n",
       "70869  Priyanka responds to user trolling her work fo...   \n",
       "25622  Mom Sridevi was worried about my comparison wi...   \n",
       "1646   Nawazuddin's 'Photograph' to screen at Berlin ...   \n",
       "46262  Congress deletes 'Sridevi awarded Padma Shri b...   \n",
       "87568  Poster of Rajinikanth's Tamil film Kaala Karik...   \n",
       "\n",
       "                                                    text  \n",
       "94403  Following PM Narendra Modi and his Bangladeshi...  \n",
       "58954  A Karnataka-based citizen journalist, formerly...  \n",
       "61347  Idea Cellular and Vodafone India on Monday sai...  \n",
       "83226  North Korea on Tuesday likened US President Do...  \n",
       "53119  A 14-year-old anaemic boy, who received repeat...  \n",
       "70869  Priyanka Chopra responded to a user on Twitter...  \n",
       "25622  Janhvi Kapoor has said her late mother and act...  \n",
       "1646   Nawazuddin Siddiqui and Sanya Malhotra starrer...  \n",
       "46262  In a tweet mourning actress Sridevi's demise, ...  \n",
       "87568  The first look poster of Rajinikanth's Tamil f...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb7ba6",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0935f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebbf4112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a25df137",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "948bda1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0696bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3e7544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62d70936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (test)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "243b832a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upGrad learner switches to career in ML & Al with 90% salary hike'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(1)\n",
    "data['headlines'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ead97a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers\n",
      "headlines: upgrad learner switches to career in ml al with salary hike\n"
     ]
    }
   ],
   "source": [
    "temp_text = data['text'][0]\n",
    "temp_headlines = data['headlines'][0]\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7286e3",
   "metadata": {},
   "source": [
    "### 훈련 데이터 전체 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6023ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f92c5cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_headlines = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dda14",
   "metadata": {},
   "source": [
    "### 빈 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0050448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec8a5fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5903070",
   "metadata": {},
   "source": [
    "# 샘플의 최대 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69652810",
   "metadata": {},
   "source": [
    "### 분포 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d6105f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (3023184205.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_324/3023184205.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    plt.title('headlines'])\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines'])\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7017446",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "headlines_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "020c6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6983507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.2755693371289142\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba59734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 27105\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33773b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "      <td>union minister dharmendra pradhan wednesday cl...</td>\n",
       "      <td>sostoken odisha cm patnaik controls mining maf...</td>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "      <td>indian space research organisation wednesday u...</td>\n",
       "      <td>sostoken isro unveils bengaluru centre for man...</td>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>killed injured in saudi arabia floods</td>\n",
       "      <td>least people killed others injured saudi arabi...</td>\n",
       "      <td>sostoken killed injured in saudi arabia floods</td>\n",
       "      <td>killed injured in saudi arabia floods eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "      <td>investigators searching lost plane carrying ar...</td>\n",
       "      <td>sostoken seat cushions from missing plane carr...</td>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "      <td>agustawestland chopper scam co accused rajiv s...</td>\n",
       "      <td>sostoken agustawestland scam accused rajiv sax...</td>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines  \\\n",
       "19  odisha cm patnaik controls mining mafia union ...   \n",
       "21  isro unveils bengaluru centre for manned space...   \n",
       "22              killed injured in saudi arabia floods   \n",
       "29  seat cushions from missing plane carrying foot...   \n",
       "36  agustawestland scam accused rajiv saxena extra...   \n",
       "\n",
       "                                                 text  \\\n",
       "19  union minister dharmendra pradhan wednesday cl...   \n",
       "21  indian space research organisation wednesday u...   \n",
       "22  least people killed others injured saudi arabi...   \n",
       "29  investigators searching lost plane carrying ar...   \n",
       "36  agustawestland chopper scam co accused rajiv s...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "19  sostoken odisha cm patnaik controls mining maf...   \n",
       "21  sostoken isro unveils bengaluru centre for man...   \n",
       "22     sostoken killed injured in saudi arabia floods   \n",
       "29  sostoken seat cushions from missing plane carr...   \n",
       "36  sostoken agustawestland scam accused rajiv sax...   \n",
       "\n",
       "                                       decoder_target  \n",
       "19  odisha cm patnaik controls mining mafia union ...  \n",
       "21  isro unveils bengaluru centre for manned space...  \n",
       "22     killed injured in saudi arabia floods eostoken  \n",
       "29  seat cushions from missing plane carrying foot...  \n",
       "36  agustawestland scam accused rajiv saxena extra...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35534074",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a70b4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2466 10173 12227 ... 10986 14627 12718]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0770b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be4e07f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 5421\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54ebc133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 21684\n",
      "훈련 레이블의 개수 : 21684\n",
      "테스트 데이터의 개수 : 5421\n",
      "테스트 레이블의 개수 : 5421\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62c67529",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "871a8bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 42646\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 30926\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11720\n",
      "단어 집합에서 희귀 단어의 비율: 72.51793837640108\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 8.30650057958748\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6055469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d444de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4081, 92, 43, 1068, 104, 831, 641, 412, 578, 135, 2826, 378, 767, 511, 4406, 4286, 251, 6461, 650, 2826, 767, 1833, 484, 2551, 7800], [355, 358, 77, 768, 4407, 528, 137, 2979, 278, 229, 42, 133, 1039, 1027, 3613, 1019, 501, 3534, 205, 1093, 38, 69, 3457, 229, 1008, 355, 1622, 3193, 3194, 3314, 1059], [4081, 92, 43, 51, 156, 219, 231, 82, 154, 3787, 69, 4169, 1009, 744, 7427, 58, 3688, 484, 919, 142, 176, 1271, 294, 82, 579, 584, 2114]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01eeb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "549d1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 18911\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 14267\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4644\n",
      "단어 집합에서 희귀 단어의 비율: 75.44286394162127\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 14.169402072472161\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ba25222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 256, 1321, 45, 570, 6, 166, 1210, 185], [1, 1114, 3, 1115, 432, 331], [1, 270, 345, 71, 101, 1712, 256], [1, 736, 262, 709, 889, 4, 421, 555], [1, 22, 1322, 169, 170, 13, 672]]\n",
      "target\n",
      "decoder  [[256, 1321, 45, 570, 6, 166, 1210, 185, 2], [1114, 3, 1115, 432, 331, 2], [270, 345, 71, 101, 1712, 256, 2], [736, 262, 709, 889, 4, 421, 555, 2], [22, 1322, 169, 170, 13, 672, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973922cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 10\n",
      "삭제할 테스트 데이터의 개수 : 1\n",
      "훈련 데이터의 개수 : 21674\n",
      "훈련 레이블의 개수 : 21674\n",
      "테스트 데이터의 개수 : 5420\n",
      "테스트 레이블의 개수 : 5420\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33961d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a412e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "643812f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c512f",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c657f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e26d4bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f2b3c",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce6f30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 77s 783ms/step - loss: 4.9162 - val_loss: 4.5445\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 65s 770ms/step - loss: 4.4981 - val_loss: 4.3428\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 65s 763ms/step - loss: 4.3169 - val_loss: 4.2095\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 65s 763ms/step - loss: 4.1740 - val_loss: 4.0919\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 64s 757ms/step - loss: 4.0390 - val_loss: 4.0112\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 64s 757ms/step - loss: 3.9186 - val_loss: 3.9121\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 64s 759ms/step - loss: 3.7952 - val_loss: 3.8206\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 64s 755ms/step - loss: 3.6642 - val_loss: 3.7162\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 65s 767ms/step - loss: 3.5389 - val_loss: 3.6356\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 64s 755ms/step - loss: 3.4284 - val_loss: 3.5715\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 64s 752ms/step - loss: 3.3301 - val_loss: 3.5231\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 64s 757ms/step - loss: 3.2401 - val_loss: 3.4888\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 64s 751ms/step - loss: 3.1570 - val_loss: 3.4563\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 64s 749ms/step - loss: 3.0800 - val_loss: 3.4250\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 64s 756ms/step - loss: 3.0075 - val_loss: 3.3973\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 64s 752ms/step - loss: 2.9409 - val_loss: 3.3946\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 64s 754ms/step - loss: 2.8752 - val_loss: 3.3684\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 64s 751ms/step - loss: 2.8158 - val_loss: 3.3561\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 63s 747ms/step - loss: 2.7567 - val_loss: 3.3618\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 64s 748ms/step - loss: 2.6992 - val_loss: 3.3411\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 64s 749ms/step - loss: 2.6417 - val_loss: 3.3447\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 64s 752ms/step - loss: 2.5895 - val_loss: 3.3363\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 64s 749ms/step - loss: 2.5377 - val_loss: 3.3398\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 64s 749ms/step - loss: 2.4872 - val_loss: 3.3344\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 64s 753ms/step - loss: 2.4382 - val_loss: 3.3402\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 64s 747ms/step - loss: 2.3925 - val_loss: 3.3381\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54c53645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ec06ff",
   "metadata": {},
   "source": [
    "# 인퍼런스 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b17f34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3595028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "323be77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "# 어텐션 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7adbe158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38bbbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b9278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6012b43c",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76622340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe923737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : international one west largest buddhist organisation admitted sexual abuse teachers organisation centres across world said take measures tackle problem letter published online international said forms abuse discrimination \n",
      "실제 요약 : admits sexual abuse by teachers \n",
      "예측 요약 :  iit university professor\n",
      "\n",
      "\n",
      "원문 : asked congress would ally jd form government karnataka congress leader ashok gehlot said yes options open meanwhile early trends counting votes show congress leading seats jd bjp ahead seats member assembly \n",
      "실제 요약 : open to with in karnataka congress \n",
      "예측 요약 :  congress to contest polls in gujarat\n",
      "\n",
      "\n",
      "원문 : manish pandey take catch point completing successfully second attempt dismiss kkr nitish rana saturday pandey also took catch near boundary dismiss russell two great catches pandey couple said bowler occasions \n",
      "실제 요약 : completes catch on second attempt \n",
      "예측 요약 :  india first ever team\n",
      "\n",
      "\n",
      "원문 : senior bcci official shukla said board considering launching mini edition ipl dubai seen huge ipl overseas earlier used stage champions league abroad still vacant thinking mini edition said shukla \n",
      "실제 요약 : bcci considering of ipl in dubai \n",
      "예측 요약 :  bcci to ipl\n",
      "\n",
      "\n",
      "원문 : aadhaar registration required children food sponsored national mission union minister kumar said parliament friday adding aadhaar would assisted field obtain said aadhaar removed need producing multiple documents prove one identity \n",
      "실제 요약 : aadhaar for food under mission \n",
      "예측 요약 :  aadhaar for aadhaar compulsory for\n",
      "\n",
      "\n",
      "원문 : following bjp failure form government karnataka congress leader sanjay said people would name dogs state governor established new record referring governor decision invite bjp form government state congress leader later apologised remark \n",
      "실제 요약 : congress leader compares karnataka to dog \n",
      "예측 요약 :  congress to be in gujarat\n",
      "\n",
      "\n",
      "원문 : noida authority started developing city biggest park cut around around trees make way park development park include two lakes multi purpose hall spread acres budget crore allocated project months \n",
      "실제 요약 : trees being cut to make noida biggest park \n",
      "예측 요약 :  bengaluru to get\n",
      "\n",
      "\n",
      "원문 : group four men allegedly kidnapped two children aged six eight family uttar pradesh thursday refused ransom lakh tortured gave children electric killed younger child police said mastermind behind kidnapping worked domestic help children house \n",
      "실제 요약 : kill of abducted kids after denied \n",
      "예측 요약 :  police police officer in gujarat\n",
      "\n",
      "\n",
      "원문 : apple recent statement said reports claiming allowed reduce accuracy iphone face id speed production completely false delay iphone production apple ceo tim cook said see happens iphone set launch officially november \n",
      "실제 요약 : iphone face report false apple \n",
      "예측 요약 :  apple faces for\n",
      "\n",
      "\n",
      "원문 : chief said money allocated budget give per month women victims triple talaq slamming central government triple talaq bill said justice women target bill seeks instant triple talaq \n",
      "실제 요약 : give per month to triple victims \n",
      "예측 요약 :  govt to ban on\n",
      "\n",
      "\n",
      "원문 : france named village favourite village year beating located north eastern france known streets half houses title friendly locals according reports \n",
      "실제 요약 : france as its village \n",
      "예측 요약 :  man from\n",
      "\n",
      "\n",
      "원문 : air intelligence unit mumbai airport customs department detained man newly released apple iphone worth search baggage checked arrived hong kong led recovery finding carrying phones gang said customs officer investigating course \n",
      "실제 요약 : iphone worth lakh seized from mumbai airport \n",
      "예측 요약 :  passengers caught gold\n",
      "\n",
      "\n",
      "원문 : white queen victoria placed temporary export ban prevent leaving uk valued around million created british sir mark golden government said hopes find within britain \n",
      "실제 요약 : uk bars of queen \n",
      "예측 요약 :  russia bans crore for\n",
      "\n",
      "\n",
      "원문 : snap ceo evan spiegel sold stock worth million marking first personal stock sale since company went public march last year sale conducted according pre arranged sales plan holdings still control company net worth around billion \n",
      "실제 요약 : ceo sells stock worth million \n",
      "예측 요약 :  apple buffett billion in day\n",
      "\n",
      "\n",
      "원문 : chief justice said supreme court go six seven months bid save funds make judiciary friendly said apex court collect records lower courts high courts need file hard copies \n",
      "실제 요약 : supreme court to go in months \n",
      "예측 요약 :  sc rejects of\n",
      "\n",
      "\n",
      "원문 : google india vice president rajan invested undisclosed sum bengaluru based online retailer us based investor chandra snapdeal former chief product officer anand also participated round founded ganesh provides women runs online help women find fit \n",
      "실제 요약 : google india invests in startup \n",
      "예측 요약 :  google to invest million in\n",
      "\n",
      "\n",
      "원문 : west bengal cm mamata banerjee friday hit centre saying super emergency going india adding every country threat said leaders today allowed speak pm narendra modi stating phone calls bjp ministers threatening sometimes \n",
      "실제 요약 : super emergency on in india mamata \n",
      "예측 요약 :  mamata to mamata in\n",
      "\n",
      "\n",
      "원문 : india sunday successfully test fired nuclear strategic ballistic missile iv dr abdul kalam island odisha coast part user trial army missile km strike range equipped advanced th generation board computer distributed seventh trial iv missile \n",
      "실제 요약 : nuclear missile successfully test fired \n",
      "예측 요약 :  india successfully test fires missile missile\n",
      "\n",
      "\n",
      "원문 : european japanese space agencies building joint mission solar system smallest least planet mercury two spacecraft one scheduled launch october would reach mercury orbit seven years later temperature third mission mercury would build nasa missions \n",
      "실제 요약 : europe japan plan mission to for \n",
      "예측 요약 :  nasa completes space station\n",
      "\n",
      "\n",
      "원문 : rss chief mohan saturday said government taking decisions rohingya situation keep mind rohingyas would definitely threat national security integrity rohingyas threat country security concern country given shelter said expressing concern issue \n",
      "실제 요약 : rohingyas threat to national security rss chief \n",
      "예측 요약 :  turkey declares emergency in israel\n",
      "\n",
      "\n",
      "원문 : users reported certain forward messages circulated whatsapp app globally android ios also freezing smartphones cases messages reportedly include special characters responsible issue one messages reads interesting read read app \n",
      "실제 요약 : whatsapp found to crash app phones \n",
      "예측 요약 :  airline rolls out of\n",
      "\n",
      "\n",
      "원문 : russia said treat us led coalition aircraft flying syria targets comes us shot russian syrian jet allegedly dropping bombs near coalition forces russia also halted air safety cooperation us syria saying us use channel avoid possible collision operation \n",
      "실제 요약 : russia to now target us aircraft in syria \n",
      "예측 요약 :  russia launches russian military\n",
      "\n",
      "\n",
      "원문 : max hospital delhi bagh resumed operations wednesday court financial commissioner stayed delhi government order revoked hospital licence hospital filed appeal following licence cancellation claiming causing inconvenience thousands patients hospital licence revoked declaring alive newborn dead \n",
      "실제 요약 : hospital operations after ban \n",
      "예측 요약 :  delhi hospital to hospital\n",
      "\n",
      "\n",
      "원문 : world debt reached record trillion worth world gross domestic product according international monetary fund world gdp debt previous peak added notably china alone contributed increase global debt since \n",
      "실제 요약 : world debt hits record high of trillion imf \n",
      "예측 요약 :  oneplus to reach trillion in\n",
      "\n",
      "\n",
      "원문 : chhattisgarh police sunday arrested naxal national rao seized one mobile phone naxal literature rao working senior technical officer national research institute hyderabad explosive expert allegedly used position institute supply arms naxals \n",
      "실제 요약 : who at research arrested \n",
      "예측 요약 :  up police arrests for police\n",
      "\n",
      "\n",
      "원문 : australian cricketer david warner wife warner said means nothing indian cricket team australian captain steve smith century ranchi test absolutely high values means nothing responded user asked indians wrong smith century \n",
      "실제 요약 : nothing to indians david warner wife \n",
      "예측 요약 :  australian cricketers smith while\n",
      "\n",
      "\n",
      "원문 : pakistan punjab province announced ban indecent movie posters displayed inside outside cinema houses province information culture minister ul hasan warned cinema house displayed indecent posters would face fines first upon violation would shut \n",
      "실제 요약 : pakistan punjab bans \n",
      "예측 요약 :  pakistan bans indian muslims\n",
      "\n",
      "\n",
      "원문 : supreme court slammed jammu kashmir government filing affidavit minority status state bench gave state government centre last chance file reply within three months discussing issues one issues whether muslims state could regarded minority \n",
      "실제 요약 : sc slams govt for status \n",
      "예측 요약 :  sc rejects ban of\n",
      "\n",
      "\n",
      "원문 : assam women university students indefinite strike permanent vice chancellor entered rd day tuesday comes state education minister said turned technical institute due lack permanent vice chancellor proper infrastructure students decision lead lower funding affect research activities \n",
      "실제 요약 : assam strike for enters rd day \n",
      "예측 요약 :  students protest against in khand\n",
      "\n",
      "\n",
      "원문 : year old post graduate student sciences allegedly committed suicide hanging residence hyderabad monday alleged suicide note claims failed several subjects college authorities personal police filed case suicide college \n",
      "실제 요약 : student kills self note blames college \n",
      "예측 요약 :  yr old commits suicide in\n",
      "\n",
      "\n",
      "원문 : tripura police friday launched probe fatwa issued facebook post announcing bounty lakh anyone would head chief minister sarkar account holder identified member world anti communist council accused cm numerous crimes credit \n",
      "실제 요약 : announces lakh for tripura cm head \n",
      "예측 요약 :  kerala to ban\n",
      "\n",
      "\n",
      "원문 : cm yogi adityanath claimed lord hanuman dalit congress leader accused yogi making remarks said conduct saint politician added cm set example society instead calls god dalit politics ali \n",
      "실제 요약 : yogi of politician \n",
      "예측 요약 :  bjp mla to bjp\n",
      "\n",
      "\n",
      "원문 : responding donald trump tweet facebook always anti trump facebook ceo mark zuckerberg said trump thinks facebook say helped trump also said last us election first time presidential candidates people using internet zuckerberg also highlighted facebook helped million people register vote \n",
      "실제 요약 : zuckerberg to trump calling facebook anti trump \n",
      "예측 요약 :  trump tweets against trump\n",
      "\n",
      "\n",
      "원문 : us court case alleging china alibaba group holdings shareholders initial public offering lawsuit claims firm regulatory warning received chinese government ipo earlier us court ruled favour alibaba dismiss claims \n",
      "실제 요약 : alibaba faces lawsuit over ipo \n",
      "예측 요약 :  us to acquire cryptocurrency cryptocurrency\n",
      "\n",
      "\n",
      "원문 : head android chrome os google saturday possible names upcoming android operating system shared google drive screenshot names food items starting oreo also said android named \n",
      "실제 요약 : google android head names for upcoming android \n",
      "예측 요약 :  android phones to be\n",
      "\n",
      "\n",
      "원문 : transgenders kerala thiruvananthapuram wednesday staged day long hunger strike front secretariat alleging violence transgenders police protestors demanded withdrawal false cases action guilty cops legislation protect rights government issued identity cards submitted demands cm pinarayi vijayan \n",
      "실제 요약 : kerala transgenders strike over police violence \n",
      "예측 요약 :  activists suspended in violence in uttarakhand\n",
      "\n",
      "\n",
      "원문 : rajput samaj uk stage demonstration outside uk parliament protest padmavati cleared country want certification padmavati revoked secretary organisation singh said film producers said screened uk theatres cleared india \n",
      "실제 요약 : group to protest against padmavati in uk \n",
      "예측 요약 :  dalit politicians in\n",
      "\n",
      "\n",
      "원문 : mark bridges gave speech seconds winning oscar best costume design speech th academy awards bridges received jet free stay luxury hotel promised oscars host jimmy said winner speech short would \n",
      "실제 요약 : the speech at oscars seconds \n",
      "예측 요약 :  india first ever ever\n",
      "\n",
      "\n",
      "원문 : india sports minister vijay goel approved appointment two foreign coaches athletics thursday goel said ministry committed providing best possible help sports infrastructure equipment athletes training preparation participation international competitions appointments include race walking metre coach \n",
      "실제 요약 : sports ministry appoints two foreign in \n",
      "예측 요약 :  sports minister announces new national sports minister\n",
      "\n",
      "\n",
      "원문 : eight member us delegation tuesday visited tibetan spiritual leader dalai lama india weeks visit leader arunachal pradesh china trip likely us relations china president donald trump seeks north korea use nuclear weapons \n",
      "실제 요약 : us visit in india \n",
      "예측 요약 :  us is us\n",
      "\n",
      "\n",
      "원문 : many people used make weighing nearly kg mexico setting guinness world record biggest mexican hoping north american free trade agreement effort notably united states president donald trump recently threatened end year old agreement \n",
      "실제 요약 : kg breaks world record \n",
      "예측 요약 :  us is the world largest\n",
      "\n",
      "\n",
      "원문 : passport billionaire jeweller nirav modi revoked connection billion pnb fraud nirav lawyer vijay aggarwal revealed ministry external affairs served notice nirav modi seeking response passport revoked however nirav reportedly replied notice raising objections notice issued \n",
      "실제 요약 : nirav modi passport over billion pnb fraud \n",
      "예측 요약 :  paid crore for nirav modi\n",
      "\n",
      "\n",
      "원문 : word non word meaning mentioned new international five years entry result editorial process referred ghost word word investigated noticed origin \n",
      "실제 요약 : english once had word without \n",
      "예측 요약 :  hawking is\n",
      "\n",
      "\n",
      "원문 : gautam lawyer accused crore agustawestland case friday arrested enforcement directorate connection fresh case money laundering possession black money whose properties delhi ncr raided last week allegedly received defence deals besides agustawestland upa tenure \n",
      "실제 요약 : accused lawyer arrested in black money case \n",
      "예측 요약 :  ed arrested in mumbai scam case\n",
      "\n",
      "\n",
      "원문 : talking tuesday chemical attack syria people killed injured us president donald trump said attack result previous barack obama led administration president obama said would establish red line use chemical weapons nothing trump claimed \n",
      "실제 요약 : trump blames syrian chemical attack on obama govt \n",
      "예측 요약 :  us missile syrian syrian in syria\n",
      "\n",
      "\n",
      "원문 : mayor warned tourists get eating food historic sites like italian authorities sites steps around said sit get instead imposing fines thought measure \n",
      "실제 요약 : tourists will get warns italian mayor \n",
      "예측 요약 :  of\n",
      "\n",
      "\n",
      "원문 : sidharth malhotra jacqueline fernandez starrer sundar released friday full characters wrote hindustan times ndtv wrote jacqueline character woman substantial significance indian express wrote plot keeps rated \n",
      "실제 요약 : sidharth jacqueline hits the theatres \n",
      "예측 요약 :  varun starrer hits the theatres\n",
      "\n",
      "\n",
      "원문 : google temporarily banning addiction centre ads globally following reports acting platform services earning huge ads showed people seeking addiction treatment huge prices google networks google announced move statement said experts find better way \n",
      "실제 요약 : google bans centre ads \n",
      "예측 요약 :  bans aadhaar data from\n",
      "\n",
      "\n",
      "원문 : monkey apparently consumed large amount alcohol began chasing customers bar following several left premises monkey would apparently visit bar regularly drinking glasses eating kept known whether monkey voluntarily consumed alcohol made drink \n",
      "실제 요약 : alcohol at bengaluru \n",
      "예측 요약 :  us bans german\n",
      "\n",
      "\n",
      "원문 : apple rolled ios update iphones new battery features iphone update ios show battery health iphone users battery needs replaced icon appear every time apple feature users personal information \n",
      "실제 요약 : apple releases with battery features new \n",
      "예측 요약 :  apple launches iphone for\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace176a",
   "metadata": {},
   "source": [
    "# 추출적 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b2b9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c35ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7a056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e55df2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('headlines:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e905a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b76ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
